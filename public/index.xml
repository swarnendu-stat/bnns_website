<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Welcome on Statistically Speaking: An R Journey</title>
    <link>/</link>
    <description>Recent content in Welcome on Statistically Speaking: An R Journey</description>
    <generator>Hugo</generator>
    <language>en-US</language>
    <lastBuildDate>Fri, 18 Apr 2025 22:21:00 +0530</lastBuildDate>
    <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Predicting Diabetes with Bayesian Neural Networks: More Than Just a Probability</title>
      <link>/post/2025/04/18/bnns-binary-classification/</link>
      <pubDate>Fri, 18 Apr 2025 22:21:00 +0530</pubDate>
      <guid>/post/2025/04/18/bnns-binary-classification/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;em&gt;In critical applications like healthcare, knowing the probability isn‚Äôt enough. Knowing how confident we are in that probability makes all the difference.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;-the-problem&#34;&gt;&#xA;  üîç The Problem&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#-the-problem&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Diabetes prediction models abound, but they often give us &lt;strong&gt;just a number&lt;/strong&gt;. Traditional classifiers like logistic regression or random forests will tell you, for instance, that there&amp;rsquo;s a 73% chance someone has diabetes.&lt;/p&gt;&#xA;&lt;p&gt;But what if we asked:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;em&gt;&amp;ldquo;How sure are we about that 73%?&amp;rdquo;&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using bnns for TMLE</title>
      <link>/post/2025/01/17/bnns-for-tmle/</link>
      <pubDate>Fri, 17 Jan 2025 23:24:25 +0530</pubDate>
      <guid>/post/2025/01/17/bnns-for-tmle/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;&#xA;  Introduction&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#introduction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;This document demonstrates how to use the &lt;a href=&#34;https://cran.r-project.org/package=bnns&#34;&gt;bnns&lt;/a&gt; package with &lt;strong&gt;TMLE&lt;/strong&gt; for causal inference. TMLE combines machine learning-based flexible models with statistical principles to produce unbiased and efficient estimators of causal effects, such as the &lt;strong&gt;Average Treatment Effect (ATE)&lt;/strong&gt;. The example also highlights how the flexibility of Bayesian Neural Networks (BNNs) can improve TMLE results when handling complex data-generating mechanisms. This tutorial borrows from this &lt;a href=&#34;https://www.khstats.com/blog/tmle/tutorial&#34;&gt;tmle tutorial&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;simulating-data&#34;&gt;&#xA;  Simulating Data&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#simulating-data&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;We simulate data where the treatment assignment and outcome are influenced by multiple covariates, and the true ATE is known.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Power of Base R: A Performance Comparison with dplyr</title>
      <link>/post/2025/01/17/power-of-base-r/</link>
      <pubDate>Fri, 17 Jan 2025 22:32:22 +0530</pubDate>
      <guid>/post/2025/01/17/power-of-base-r/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;&#xA;  Introduction&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#introduction&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;This presentation explores the performance differences between base R and the dplyr package for various data manipulation tasks.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;While dplyr is renowned for its intuitive syntax and efficiency,&lt;/li&gt;&#xA;&lt;li&gt;base R functions can sometimes outperform it, particularly in large simulations.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Understanding these differences can aid in making informed decisions when choosing data wrangling techniques.&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-iris-dataset&#34;&gt;&#xA;  The Iris Dataset&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#the-iris-dataset&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;The &lt;strong&gt;iris&lt;/strong&gt; dataset is a classic dataset in statistics and machine learning, often used for demonstrating data manipulation and analysis techniques.&lt;/p&gt;</description>
    </item>
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Fri, 17 Jan 2025 00:00:00 +0530</pubDate>
      <guid>/about/</guid>
      <description>&lt;h2 id=&#34;about-me&#34;&gt;&#xA;  About Me&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#about-me&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Welcome to my blog!&lt;/p&gt;&#xA;&lt;p&gt;I‚Äôm an experienced statistician and an avid &lt;code&gt;R&lt;/code&gt; enthusiast. Over the years, &lt;code&gt;R&lt;/code&gt; has become an integral part of my professional and personal toolkit. Whether it‚Äôs performing advanced statistical modeling, developing data visualizations, or exploring machine learning algorithms, I believe &lt;code&gt;R&lt;/code&gt; empowers users to push the boundaries of data analysis.&lt;/p&gt;&#xA;&lt;p&gt;This blog is my humble attempt to share what I‚Äôve learned and continue to learn. Here, you‚Äôll find tutorials, tips, and insights about:&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
